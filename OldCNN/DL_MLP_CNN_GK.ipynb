{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading GK matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects as robjects\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Load the Rdata file\n",
    "robjects.r('load(\"../Geno/GKL.RData\")')\n",
    "\n",
    "# Get the list from the Rdata file\n",
    "G_control_025 = robjects.r('GKL$Control$GK0.25')\n",
    "G_control_15 = robjects.r('GKL$Control$GK0.25')\n",
    "# G_stress = robjects.r('GL$Stress')\n",
    "\n",
    "# # Convert into numpy array\n",
    "G_con_025 = pd.DataFrame(np.reshape(G_control_025, (G_control_025.nrow, G_control_025.ncol)), columns = G_control_025.colnames, index = G_control_025.rownames)\n",
    "G_con_15 = pd.DataFrame(np.reshape(G_control_15, (G_control_15.nrow, G_control_15.ncol)), columns = G_control_15.colnames, index = G_control_15.rownames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "metL = []\n",
    "for i in range(1, 31):\n",
    "    metL.append(pd.read_csv('../Met/CrossValidation/cv_' + str(i) + '/met_cv_' + str(i) + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def met_read(met_cv1):\n",
    "\n",
    "    # met_cv1 = pd.read_csv('../Met/CrossValidation/cv_1/met_cv_1.csv')\n",
    "    met_con_cv1_train = met_cv1.query(\"Treatment=='Control' and set == 'train'\")\n",
    "    met_con_cv1_test = met_cv1.query(\"Treatment=='Control' and set == 'test'\")\n",
    "    train_id = np.array(met_con_cv1_train.NSFTV_ID)\n",
    "    test_id = np.array(met_con_cv1_test.NSFTV_ID)\n",
    "\n",
    "    G_con_train025 = G_con_025.loc[train_id, ] #155*155\n",
    "    G_con_test025 = G_con_025.loc[test_id, ] #38*38\n",
    "    G_con_train15 = G_con_15.loc[train_id, ] #155*155\n",
    "    G_con_test15 = G_con_15.loc[test_id, ]\n",
    "    # Convert pd.dataframe into np.array\n",
    "    X_train025 = np.array(G_con_train025)\n",
    "    X_test025 = np.array(G_con_test025)\n",
    "    X_train15 = np.array(G_con_train15)\n",
    "    X_test15 = np.array(G_con_test15)\n",
    "    Y_train = np.array(met_con_cv1_train.iloc[:,2]) #remove Treatment, set columns \n",
    "                                                    #just keep metabolie a1\n",
    "    Y_test = np.array(met_con_cv1_test.iloc[:,2]) #remove Treatment, set columns \n",
    "                                                #just keep metabolie a1\n",
    "    # print('X_train shape is:', X_train.shape)\n",
    "    # print('X_test shape is:', X_test.shape)\n",
    "    # print('Y_train shape is:', Y_train.shape)\n",
    "    # print('Y_test shape is:', Y_test.shape)\n",
    "\n",
    "    return X_train025, X_test025, X_train15, X_test15, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train025, X_test025, X_train15, X_test15, Y_train, Y_test = met_read(metL[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y-net for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv1D, Flatten, GlobalAveragePooling1D, GlobalMaxPool1D, MaxPool1D, Dropout, Input, concatenate, Activation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_build(input_shape, batch_size,kernel_size,dropout,n_filters):\n",
    "    \n",
    "    # left branch of Y network\n",
    "    left_inputs = Input(shape=input_shape)\n",
    "    x = left_inputs\n",
    "    filters = n_filters\n",
    "    # 3 layers of Conv2D-Dropout-MaxPooling2D\n",
    "    # number of filters doubles after each layer (32-64-128)\n",
    "    for i in range(3):\n",
    "        x = Conv1D(filters=filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  padding='same',\n",
    "                  activation='relu')(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = MaxPooling1D()(x)\n",
    "        filters *= 2\n",
    "\n",
    "    # right branch of Y network\n",
    "    right_inputs = Input(shape=input_shape)\n",
    "    y = right_inputs\n",
    "    filters = n_filters\n",
    "    # 3 layers of Conv2D-Dropout-MaxPooling2D\n",
    "    # number of filters doubles after each layer (32-64-128)\n",
    "    for i in range(3):\n",
    "        y = Conv1D(filters=filters,\n",
    "                  kernel_size=kernel_size, #3*3\n",
    "                  padding='same', #padding zeros\n",
    "                  activation='relu',\n",
    "                  dilation_rate=2)(y)\n",
    "        y = Dropout(dropout)(y)\n",
    "        y = MaxPooling1D()(y) #pool_size=(2, 2) default\n",
    "        filters *= 2\n",
    "\n",
    "    # merge left and right branches outputs\n",
    "    z = concatenate([x, y])\n",
    "    # feature maps to vector in preparation to connecting to Dense layer\n",
    "    z = Flatten()(z)\n",
    "    z = Dropout(dropout)(z)\n",
    "    outputs = Dense(num_labels, activation='softmax')(z)\n",
    "\n",
    "    # build the model in functional API\n",
    "    model = Model([left_inputs, right_inputs], outputs)\n",
    "    # verify the model using graph\n",
    "    # plot_model(model, to_file='cnn-y-network.png', show_shapes=True)\n",
    "    # verify the model using layer text description\n",
    "    print(model.summary())\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def CNN(X_train025, X_test025, X_train15, X_test15, Y_train, Y_test):\n",
    "\n",
    "    seed=616\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, 8, activation=\"relu\", input_shape=(193,1)))\n",
    "    # model.add(Conv1D(64, 8, activation=\"relu\"))\n",
    "    # model.add(Conv1D(128, 8, activation=\"relu\"))\n",
    "    # model.add(Conv1D(512, 8, activation=\"relu\"))\n",
    "    # model.add(Conv1D(32, 8, activation=\"relu\"))\n",
    "    # model.add(GlobalAveragePooling1D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "    opt = keras.optimizers.legacy.Adam(learning_rate=1e-5)\n",
    "    model.compile(loss=\"mse\", optimizer=opt, metrics=['mse'])\n",
    "    # model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "    history_cnn = model.fit(X_train, Y_train, \n",
    "                            batch_size=12,\n",
    "                            epochs=200, \n",
    "                            verbose=0,\n",
    "                            validation_data=(X_test, Y_test),\n",
    "                            callbacks=[early_stopping])\n",
    "\n",
    "    Y_pred = model.predict(X_test).reshape(38)\n",
    "\n",
    "    print(\"MSE:\", mean_squared_error(Y_test, Y_pred))\n",
    "    print(\"Corr:\", np.corrcoef(Y_test, Y_pred)[0,1])\n",
    "\n",
    "\n",
    "    print('############################ \\n')\n",
    "    \n",
    "    # return history_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 1):\n",
    "    print(\"NOW is running met #\", i+1)\n",
    "    X_train, X_test, Y_train, Y_test = met_read(metL[i])\n",
    "    history_cnn = CNN(X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_cnn.history['loss'], label='loss')\n",
    "plt.plot(history_cnn.history['val_loss'], label = 'val_loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('LOSS')\n",
    "plt.legend(loc='upper right')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLmet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
