{"cells":[{"cell_type":"markdown","metadata":{"id":"MwO5c5ZUiTiz"},"source":["![](https://github.com/rajeevratan84/ModernComputerVision/raw/main/logo_MCV_W.png)\n","\n","# **Keras - Transfer Learning with Cats vs Dogs**\n","\n","---\n","\n","In this lesson, we learn how to setup data generators to load our own dataset and train a classifier using Keras. \n","1. Understand trainable layers of a Neural Network\n","2. Setting up our data\n","3. Building our Model for Transfer Learning\n","4. Perform Fine Tuning"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2981,"status":"ok","timestamp":1646367642537,"user":{"displayName":"Archit Sorathiya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16296646542609532734"},"user_tz":-330},"id":"6_MOzgCDiEDZ"},"outputs":[],"source":["# Import of libraries\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","import random\n"]},{"cell_type":"markdown","metadata":{"id":"ljhpFRAuitzW"},"source":["## **Trainable Layers**\n","\n","Layers & models have **three** weight attributes:\n","\n","- `weights` is the list of all weights variables of the layer.\n","- `trainable_weights` is the list of those that are meant to be updated (via gradient\n"," descent) to minimize the loss during training.\n","- `non_trainable_weights` is the list of those that aren't meant to be trained.\n"," Typically they are updated by the model during the forward pass.\n","\n","**Example: the `Dense` layer has 2 trainable weights (kernel & bias)**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":464,"status":"ok","timestamp":1646367647948,"user":{"displayName":"Archit Sorathiya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16296646542609532734"},"user_tz":-330},"id":"OorMx0WYipc7","outputId":"ce78a947-7a5f-4102-eb1e-137f7f30be6e"},"outputs":[],"source":["# layer = keras.layers.Dense(4)\n","\n","# # Create the weights using layer.build\n","# layer.build((None, 2))  \n","\n","# print(f'Number of weights: {len(layer.weights)}')\n","# print(f'Number of trainable_weights: {len(layer.trainable_weights)}')\n","# print(f'Number of non_trainable_weights: {len(layer.non_trainable_weights)}')"]},{"cell_type":"markdown","metadata":{"id":"6phLYRHYk9yX"},"source":["All layers are trainable with the exception of **BatchNormalization**. It uses non-trainable weights to keep track of the mean and variance of its inputs during training. "]},{"cell_type":"markdown","metadata":{"id":"ulQQxkmslaY1"},"source":["**Layers & models** also feature a boolean attribute `trainable`. \n","\n","Its value can be changed by setting `layer.trainable` to `False` moves all the layer's weights from trainable to non-trainable.  \n","\n","This is called **\"freezing\"** the layer: the state of a frozen layer won't\n","be updated during training (either when training with `fit()` or when training with\n"," any custom loop that relies on `trainable_weights` to apply gradient updates).\n","\n","### **Example: setting `trainable` to `False`**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1257,"status":"ok","timestamp":1646367658350,"user":{"displayName":"Archit Sorathiya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16296646542609532734"},"user_tz":-330},"id":"WWHk1oT4lKzM","outputId":"6d0ca77a-5770-446f-f26f-6317738a7e82"},"outputs":[],"source":["# # Make a model with 2 layers\n","# layer1 = keras.layers.Dense(3, activation=\"relu\")\n","# layer2 = keras.layers.Dense(3, activation=\"sigmoid\")\n","# model = keras.Sequential([keras.Input(shape=(3,)), layer1, layer2])\n","\n","# # Freeze the first layer\n","# layer1.trainable = False\n","\n","# # Keep a copy of the weights of layer1 for later reference\n","# initial_layer1_weights_values = layer1.get_weights()\n","\n","# # Train the model\n","# model.compile(optimizer=\"adam\", loss=\"mse\")\n","# model.fit(np.random.random((2, 3)), np.random.random((2, 3)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":479,"status":"ok","timestamp":1646367664628,"user":{"displayName":"Archit Sorathiya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16296646542609532734"},"user_tz":-330},"id":"FGX1RiExiR9P","outputId":"b83dcaea-41e4-4615-d041-be15f736c26f"},"outputs":[],"source":["# # Check that the weights of layer1 have not changed during training\n","# final_layer1_weights_values = layer1.get_weights()\n","\n","# if initial_layer1_weights_values[0].all() == final_layer1_weights_values[0].all():\n","#   print('Weights unchanged')\n","\n","# if initial_layer1_weights_values[1].all() == final_layer1_weights_values[1].all():\n","#   print('Weights unchanged')"]},{"cell_type":"markdown","metadata":{"id":"tuinAOo8oM7K"},"source":["**Note**: **`.trianable` is Recursive**, meaning that on a model or on any layer that has sublayers, all children layers become non-trainable as well."]},{"cell_type":"markdown","metadata":{"id":"gvWJ_T_Bonok"},"source":["## **Implementing Transfer Learning**\n","\n","![](https://github.com/rajeevratan84/ModernComputerVision/blob/main/Screenshot%202021-05-11%20at%2011.49.01%20pm.png?raw=true)\n","\n","## **Transfer-learning workflow**\n","\n","1. We instantiate a **base model and load pre-trained weighs** into it.\n","2. **Freeze** all layers in the base model by setting `trainable = False`.\n","3. Create a **new model on top** of the output of one (or several) layers from the base\n"," model.\n","4. Train your new model on your new dataset."]},{"cell_type":"markdown","metadata":{"id":"zWZEzvExtCL8"},"source":["### **Step 1. Load a base model with pre-trained weights (ImageNet)**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23507,"status":"ok","timestamp":1646367694838,"user":{"displayName":"Archit Sorathiya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16296646542609532734"},"user_tz":-330},"id":"60ZNFnW42Kq3","outputId":"fb1e4740-e665-46b6-874f-5d5ddfc13152"},"outputs":[],"source":["# import tensorflow_datasets as tfds\n","\n","# tfds.disable_progress_bar()\n","\n","# train_ds, validation_ds, test_ds = tfds.load(\n","#     \"cats_vs_dogs\",\n","#     # Reserve 10% for validation and 10% for test\n","#     split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n","#     as_supervised=True,  # Include labels\n","# )\n","\n","# print(f'Number of training samples: {tf.data.experimental.cardinality(train_ds)}')\n","# print(f'Number of validation samples: {tf.data.experimental.cardinality(validation_ds)}')\n","# print(f'Number of test samples: {tf.data.experimental.cardinality(test_ds)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":591},"executionInfo":{"elapsed":2738,"status":"ok","timestamp":1646367726432,"user":{"displayName":"Archit Sorathiya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16296646542609532734"},"user_tz":-330},"id":"7Yil6T-H2Zg0","outputId":"2994d0fb-03ca-41a9-8b61-91c4e9cb5839"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"UBc0fkwp2qEX"},"source":["## **Standardize Our Data**\n","\n","- Standardize to a fixed image size. We pick 150x150.\n","- Normalize pixel values between -1 and 1. We'll do this using a `Normalization` layer as\n"," part of the model itself."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import pandas as pd \n","import numpy as np\n","import os\n","from scipy.stats import zscore\n","\n","from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n","from tensorflow.keras.applications import VGG16, imagenet_utils\n","# from keras.callbacks import EarlyStopping\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>NSFTV_ID</th>\n","      <th>Treatment</th>\n","      <th>hexanoic acid</th>\n","      <th>alanine</th>\n","      <th>valine</th>\n","      <th>urea</th>\n","      <th>ethanolamine</th>\n","      <th>leucine</th>\n","      <th>glycerol</th>\n","      <th>nicotinic acid</th>\n","      <th>...</th>\n","      <th>adenosine</th>\n","      <th>trehalose</th>\n","      <th>maltose</th>\n","      <th>sophorose</th>\n","      <th>melibiose</th>\n","      <th>isomaltose</th>\n","      <th>galactinol</th>\n","      <th>phosphoric acid</th>\n","      <th>Sucrose</th>\n","      <th>Raffinose</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NSFTV_1</td>\n","      <td>Control</td>\n","      <td>0.073463</td>\n","      <td>0.099932</td>\n","      <td>0.004720</td>\n","      <td>1.853639</td>\n","      <td>-0.269819</td>\n","      <td>-0.055739</td>\n","      <td>0.510914</td>\n","      <td>0.391473</td>\n","      <td>...</td>\n","      <td>0.046634</td>\n","      <td>-0.450524</td>\n","      <td>-0.308289</td>\n","      <td>-0.063850</td>\n","      <td>0.423776</td>\n","      <td>0.314369</td>\n","      <td>0.158955</td>\n","      <td>-0.140715</td>\n","      <td>0.402484</td>\n","      <td>-1.440777</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NSFTV_102</td>\n","      <td>Control</td>\n","      <td>-0.015095</td>\n","      <td>0.209659</td>\n","      <td>0.127870</td>\n","      <td>-0.101918</td>\n","      <td>-0.437334</td>\n","      <td>0.239351</td>\n","      <td>0.055266</td>\n","      <td>-0.028396</td>\n","      <td>...</td>\n","      <td>0.121284</td>\n","      <td>-0.065042</td>\n","      <td>0.368929</td>\n","      <td>-0.008045</td>\n","      <td>0.399713</td>\n","      <td>-0.264498</td>\n","      <td>-0.061229</td>\n","      <td>-0.235017</td>\n","      <td>-0.741653</td>\n","      <td>1.070465</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NSFTV_103</td>\n","      <td>Control</td>\n","      <td>0.160103</td>\n","      <td>0.633219</td>\n","      <td>0.151433</td>\n","      <td>-0.387669</td>\n","      <td>0.734534</td>\n","      <td>0.257577</td>\n","      <td>0.296091</td>\n","      <td>0.659027</td>\n","      <td>...</td>\n","      <td>0.361614</td>\n","      <td>-0.095921</td>\n","      <td>1.005878</td>\n","      <td>0.057135</td>\n","      <td>0.015705</td>\n","      <td>-0.009189</td>\n","      <td>0.044330</td>\n","      <td>0.834154</td>\n","      <td>0.303034</td>\n","      <td>-0.603933</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NSFTV_104</td>\n","      <td>Control</td>\n","      <td>-0.013302</td>\n","      <td>1.181448</td>\n","      <td>2.265878</td>\n","      <td>-0.359049</td>\n","      <td>2.272740</td>\n","      <td>2.541394</td>\n","      <td>1.046026</td>\n","      <td>0.542261</td>\n","      <td>...</td>\n","      <td>0.331713</td>\n","      <td>-0.479455</td>\n","      <td>1.581037</td>\n","      <td>0.250587</td>\n","      <td>-0.221493</td>\n","      <td>2.584905</td>\n","      <td>0.217831</td>\n","      <td>1.466190</td>\n","      <td>-0.346015</td>\n","      <td>-2.386452</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NSFTV_105</td>\n","      <td>Control</td>\n","      <td>0.328212</td>\n","      <td>0.459086</td>\n","      <td>0.923531</td>\n","      <td>-0.247979</td>\n","      <td>1.909945</td>\n","      <td>0.371542</td>\n","      <td>0.246153</td>\n","      <td>-0.041397</td>\n","      <td>...</td>\n","      <td>0.674103</td>\n","      <td>0.312100</td>\n","      <td>0.409481</td>\n","      <td>0.196645</td>\n","      <td>-0.313199</td>\n","      <td>0.029189</td>\n","      <td>0.038495</td>\n","      <td>1.258600</td>\n","      <td>-0.338108</td>\n","      <td>-0.278003</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>157</th>\n","      <td>NSFTV_90</td>\n","      <td>Control</td>\n","      <td>0.154189</td>\n","      <td>-0.032636</td>\n","      <td>-0.143583</td>\n","      <td>0.443690</td>\n","      <td>-0.013267</td>\n","      <td>-0.008876</td>\n","      <td>-0.090771</td>\n","      <td>-0.303796</td>\n","      <td>...</td>\n","      <td>-0.009423</td>\n","      <td>-0.107175</td>\n","      <td>-0.492381</td>\n","      <td>0.162906</td>\n","      <td>0.192797</td>\n","      <td>-0.192028</td>\n","      <td>-0.061853</td>\n","      <td>0.285540</td>\n","      <td>-0.293308</td>\n","      <td>1.110043</td>\n","    </tr>\n","    <tr>\n","      <th>158</th>\n","      <td>NSFTV_92</td>\n","      <td>Control</td>\n","      <td>-0.028981</td>\n","      <td>-0.115577</td>\n","      <td>0.092292</td>\n","      <td>0.029275</td>\n","      <td>0.301546</td>\n","      <td>0.119252</td>\n","      <td>-0.139018</td>\n","      <td>-0.114555</td>\n","      <td>...</td>\n","      <td>-0.014101</td>\n","      <td>0.000017</td>\n","      <td>0.187861</td>\n","      <td>0.185697</td>\n","      <td>-0.062153</td>\n","      <td>0.097698</td>\n","      <td>-0.018249</td>\n","      <td>-1.020564</td>\n","      <td>0.129552</td>\n","      <td>0.339379</td>\n","    </tr>\n","    <tr>\n","      <th>159</th>\n","      <td>NSFTV_93</td>\n","      <td>Control</td>\n","      <td>-0.005575</td>\n","      <td>-0.058799</td>\n","      <td>0.191081</td>\n","      <td>0.850514</td>\n","      <td>0.222220</td>\n","      <td>0.368702</td>\n","      <td>0.316836</td>\n","      <td>-0.092219</td>\n","      <td>...</td>\n","      <td>-0.028387</td>\n","      <td>0.096424</td>\n","      <td>-0.680553</td>\n","      <td>0.072835</td>\n","      <td>-0.321447</td>\n","      <td>-0.169982</td>\n","      <td>-0.083892</td>\n","      <td>-0.118708</td>\n","      <td>-0.248154</td>\n","      <td>-0.093230</td>\n","    </tr>\n","    <tr>\n","      <th>160</th>\n","      <td>NSFTV_96</td>\n","      <td>Control</td>\n","      <td>0.153888</td>\n","      <td>0.111901</td>\n","      <td>-0.248869</td>\n","      <td>-0.651881</td>\n","      <td>0.206074</td>\n","      <td>-0.088784</td>\n","      <td>0.612490</td>\n","      <td>-0.194678</td>\n","      <td>...</td>\n","      <td>0.152969</td>\n","      <td>-0.355506</td>\n","      <td>-0.008856</td>\n","      <td>-0.335311</td>\n","      <td>-0.224398</td>\n","      <td>-0.036093</td>\n","      <td>-0.095945</td>\n","      <td>-0.003359</td>\n","      <td>-0.093124</td>\n","      <td>-1.008269</td>\n","    </tr>\n","    <tr>\n","      <th>161</th>\n","      <td>NSFTV_99</td>\n","      <td>Control</td>\n","      <td>-0.015641</td>\n","      <td>0.514069</td>\n","      <td>0.104843</td>\n","      <td>0.346490</td>\n","      <td>0.006381</td>\n","      <td>0.248585</td>\n","      <td>-0.170419</td>\n","      <td>0.306622</td>\n","      <td>...</td>\n","      <td>-0.043124</td>\n","      <td>0.141829</td>\n","      <td>0.037727</td>\n","      <td>0.320464</td>\n","      <td>0.104561</td>\n","      <td>-0.062014</td>\n","      <td>0.087381</td>\n","      <td>-0.094175</td>\n","      <td>-0.232037</td>\n","      <td>0.201607</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>162 rows × 68 columns</p>\n","</div>"],"text/plain":["      NSFTV_ID Treatment  hexanoic acid   alanine    valine      urea  \\\n","0      NSFTV_1   Control       0.073463  0.099932  0.004720  1.853639   \n","1    NSFTV_102   Control      -0.015095  0.209659  0.127870 -0.101918   \n","2    NSFTV_103   Control       0.160103  0.633219  0.151433 -0.387669   \n","3    NSFTV_104   Control      -0.013302  1.181448  2.265878 -0.359049   \n","4    NSFTV_105   Control       0.328212  0.459086  0.923531 -0.247979   \n","..         ...       ...            ...       ...       ...       ...   \n","157   NSFTV_90   Control       0.154189 -0.032636 -0.143583  0.443690   \n","158   NSFTV_92   Control      -0.028981 -0.115577  0.092292  0.029275   \n","159   NSFTV_93   Control      -0.005575 -0.058799  0.191081  0.850514   \n","160   NSFTV_96   Control       0.153888  0.111901 -0.248869 -0.651881   \n","161   NSFTV_99   Control      -0.015641  0.514069  0.104843  0.346490   \n","\n","     ethanolamine   leucine  glycerol  nicotinic acid  ...  adenosine  \\\n","0       -0.269819 -0.055739  0.510914        0.391473  ...   0.046634   \n","1       -0.437334  0.239351  0.055266       -0.028396  ...   0.121284   \n","2        0.734534  0.257577  0.296091        0.659027  ...   0.361614   \n","3        2.272740  2.541394  1.046026        0.542261  ...   0.331713   \n","4        1.909945  0.371542  0.246153       -0.041397  ...   0.674103   \n","..            ...       ...       ...             ...  ...        ...   \n","157     -0.013267 -0.008876 -0.090771       -0.303796  ...  -0.009423   \n","158      0.301546  0.119252 -0.139018       -0.114555  ...  -0.014101   \n","159      0.222220  0.368702  0.316836       -0.092219  ...  -0.028387   \n","160      0.206074 -0.088784  0.612490       -0.194678  ...   0.152969   \n","161      0.006381  0.248585 -0.170419        0.306622  ...  -0.043124   \n","\n","     trehalose   maltose  sophorose  melibiose  isomaltose  galactinol  \\\n","0    -0.450524 -0.308289  -0.063850   0.423776    0.314369    0.158955   \n","1    -0.065042  0.368929  -0.008045   0.399713   -0.264498   -0.061229   \n","2    -0.095921  1.005878   0.057135   0.015705   -0.009189    0.044330   \n","3    -0.479455  1.581037   0.250587  -0.221493    2.584905    0.217831   \n","4     0.312100  0.409481   0.196645  -0.313199    0.029189    0.038495   \n","..         ...       ...        ...        ...         ...         ...   \n","157  -0.107175 -0.492381   0.162906   0.192797   -0.192028   -0.061853   \n","158   0.000017  0.187861   0.185697  -0.062153    0.097698   -0.018249   \n","159   0.096424 -0.680553   0.072835  -0.321447   -0.169982   -0.083892   \n","160  -0.355506 -0.008856  -0.335311  -0.224398   -0.036093   -0.095945   \n","161   0.141829  0.037727   0.320464   0.104561   -0.062014    0.087381   \n","\n","     phosphoric acid   Sucrose  Raffinose  \n","0          -0.140715  0.402484  -1.440777  \n","1          -0.235017 -0.741653   1.070465  \n","2           0.834154  0.303034  -0.603933  \n","3           1.466190 -0.346015  -2.386452  \n","4           1.258600 -0.338108  -0.278003  \n","..               ...       ...        ...  \n","157         0.285540 -0.293308   1.110043  \n","158        -1.020564  0.129552   0.339379  \n","159        -0.118708 -0.248154  -0.093230  \n","160        -0.003359 -0.093124  -1.008269  \n","161        -0.094175 -0.232037   0.201607  \n","\n","[162 rows x 68 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["met_control = pd.read_csv(\"../../Met/met_rr_control_named.csv\")\n","met_control"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["0     -0.002920\n","1     -0.027671\n","2      0.128017\n","3      0.155692\n","4      0.071120\n","         ...   \n","157   -0.008483\n","158   -0.010560\n","159   -0.026614\n","160    0.009631\n","161    0.013490\n","Name: glyceric acid, Length: 162, dtype: float64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["met_control[\"glyceric acid\"]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["labels = zscore(np.array(met_control.glycerol)) #normalization\n","# labels = np.array(met_control.glycerol)\n","# print(labels)\n","plt.hist(labels)\n","lines = np.array(met_control.NSFTV_ID)\n","# print(lines)\n","\n","dff = pd.DataFrame({\n","        \"labels\": labels,\n","        \"NSFTV_ID\": lines\n","    })\n","\n","dff.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset_path = \"../../SNPimg/dataset/\"\n","chr_path = os.listdir(\"../../SNPimg/dataset/NSFTV_1/\")\n","base_df = dff.assign(dataset_path=dataset_path)\n","base_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_pathss = [base_df[\"dataset_path\"] + base_df[\"NSFTV_ID\"] + \"/\" + chr_path[i] for i in range(12)]  ####### here we can include multiple chromosome setting.\n","# print(image_paths)\n","print(np.array(image_pathss).shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_pathss[1]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image_total = []\n","\n","# loop over each batch\n","\n","for image_paths in image_pathss:\n","  # print(image_paths)\n","  batch_size = 162\n","  # image_features_chr = []\n","  image_labels = []\n","  # image_paths = image_pathss[0]\n","  for i in range(0, len(image_paths)//batch_size):\n","    # print(i)\n","    batch_paths = image_paths[i:i + batch_size]\n","    batch_labels = dff[\"labels\"][i:i + batch_size]\n","    batch_images = []\n","    for image_path in batch_paths:\n","      image = load_img(image_path, target_size = (224, 224)) #image is still in PIL format. Need to convert into np.array\n","      image = img_to_array(image)\n","      # We expand the dimensions and then subtract the mean RGB pixel intensity of ImageNet\n","      image = np.expand_dims(image, axis=0) # add one dim in axis=0\n","      image = imagenet_utils.preprocess_input(image) #normalization based on ImageNet.\n","      batch_images.append(image)\n","    \n","    batch_images = np.vstack(batch_images) #looks like no need to expand in the before lines.\n","    # features = model.predict(batch_images, batch_size = batch_size)\n","    # print(features.shape)\n","    # features = np.reshape(features,(-1, features.shape[1]*features.shape[2]*features.shape[3]))\n","    # print(features.shape)\n","    # # store our features and corresponding labels\n","    # image_features_chr.append(features)\n","    image_labels.append(batch_labels)\n","\n","  image_total.append(batch_images)\n","\n","# image_features.append(np.array(image_features_chr))  "]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["i = 1\n","i = str(i)\n","cvv = pd.read_csv(\"../../Met/CrossValidation/cv_\"+i+\"/met_cv_\"+i+\".csv\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_index = cvv.query(\"Treatment=='Control' and set == 'train'\").index\n","test_index = cvv.query(\"Treatment=='Control' and set == 'test'\").index\n","\n","train_labels = batch_labels[train_index]\n","test_labels = batch_labels[test_index]\n","\n","Train_image = []\n","Test_image = []\n","for chrr in range(0,12):\n","    train_images = image_total[chrr][train_index,:,:,:]\n","    test_images = image_total[chrr][test_index,:,:,:]\n","    \n","    Train_image.append(train_images)\n","    Test_image.append(test_images)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["size = (150, 150)\n","\n","def newdataset_ge(inputs, targets, size):\n","    inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)  # Adjust dtype as needed\n","    targets = tf.convert_to_tensor(targets, dtype=tf.float32)  # Adjust dtype as needed\n","\n","    # Create a dataset using from_tensor_slices\n","    new_dataset = tf.data.Dataset.from_tensor_slices(({\"inputs1\": tf.image.resize(inputs[0], size=size), \n","                                                       \"inputs2\": tf.image.resize(inputs[1], size=size), \n","                                                       \"inputs3\":tf.image.resize(inputs[2], size=size),\n","                                                       \"inputs4\": tf.image.resize(inputs[3], size=size), \n","                                                       \"inputs5\": tf.image.resize(inputs[4], size=size), \n","                                                       \"inputs6\":tf.image.resize(inputs[5], size=size),\n","                                                       \"inputs7\": tf.image.resize(inputs[6], size=size), \n","                                                       \"inputs8\": tf.image.resize(inputs[7], size=size), \n","                                                       \"inputs9\":tf.image.resize(inputs[8], size=size),\n","                                                       \"inputs10\": tf.image.resize(inputs[9], size=size), \n","                                                       \"inputs11\": tf.image.resize(inputs[10], size=size), \n","                                                       \"inputs12\":tf.image.resize(inputs[11], size=size)}, \n","                                                       targets))\n","    return new_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_ds = newdataset_ge(Train_image, train_labels, size)\n","test_ds = newdataset_ge(Test_image, test_labels, size)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(10, 10))\n","for i, data in enumerate(train_ds.take(9)):\n","    # print(label)\n","    ax = plt.subplot(3, 3, i + 1)\n","    plt.imshow(data[0][\"inputs1\"])\n","    # plt.title('Cat' if int(label) == 0 else 'Dog')\n","    plt.title(i)\n","    plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":464,"status":"ok","timestamp":1646367765377,"user":{"displayName":"Archit Sorathiya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16296646542609532734"},"user_tz":-330},"id":"gUwfIJkQ2kKf"},"outputs":[],"source":["# size = (150, 150)\n","\n","# train_ds = train_ds.map(lambda x, y: (tf.image.resize(x[\"inputs1\"], size), y))\n","# validation_ds = validation_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n","# test_ds = test_ds.map(lambda x, y: (tf.image.resize(x, size), y))"]},{"cell_type":"markdown","metadata":{"id":"qQCMcdoX3WZc"},"source":["We'll batch the data and use caching & prefetching to optimize loading speed."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":447,"status":"ok","timestamp":1646367771527,"user":{"displayName":"Archit Sorathiya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16296646542609532734"},"user_tz":-330},"id":"NtRttIKn3SiN"},"outputs":[],"source":["batch_size = 8\n","\n","train_ds = train_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n","# validation_ds = validation_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n","test_ds = test_ds.cache().batch(batch_size).prefetch(buffer_size=10)"]},{"cell_type":"markdown","metadata":{"id":"U86AjS5t4Kk8"},"source":["### **Introduce some random data augmentation**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":453,"status":"ok","timestamp":1646367775417,"user":{"displayName":"Archit Sorathiya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16296646542609532734"},"user_tz":-330},"id":"A2ZnAgib4JmD"},"outputs":[],"source":["# from tensorflow import keras\n","# from tensorflow.keras import layers\n","\n","# data_augmentation = keras.Sequential(\n","#     [\n","#         layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n","#         layers.experimental.preprocessing.RandomRotation(0.1),\n","#     ]\n","# )"]},{"cell_type":"markdown","metadata":{"id":"2UbIwZ_S32X4"},"source":["#### **Visualize our Data Augmentations**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":591},"executionInfo":{"elapsed":3199,"status":"ok","timestamp":1646367782005,"user":{"displayName":"Archit Sorathiya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16296646542609532734"},"user_tz":-330},"id":"V3lVNdpE31V3","outputId":"fdc07483-1f9d-427e-c903-fad4a7f67de8"},"outputs":[],"source":["# import numpy as np\n","\n","# for images, labels in train_ds.take(1):\n","#     plt.figure(figsize=(10, 10))\n","#     first_image = images[0]\n","#     for i in range(9):\n","#         ax = plt.subplot(3, 3, i + 1)\n","#         augmented_image = data_augmentation(\n","#             tf.expand_dims(first_image, 0), training=True\n","#         )\n","#         plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\n","#         plt.title(int(labels[i]))\n","#         plt.axis(\"off\")"]},{"cell_type":"markdown","metadata":{"id":"1C7vwVEd4hLf"},"source":["## **3. Building our model**\n","\n","Now let's built a model that follows the blueprint we've explained earlier.\n","\n","Note that:\n","\n","- We add a `Normalization` layer to scale input values (initially in the `[0, 255]`\n"," range) to the `[-1, 1]` range.\n","- We add a `Dropout` layer before the classification layer, for regularization.\n","- We make sure to pass `training=False` when calling the base model, so that\n","it runs in inference mode, so that batchnorm statistics don't get updated\n","even after we unfreeze the base model for fine-tuning.\n","\n","- We'll be using the **Xception Model** as our base."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5947,"status":"ok","timestamp":1646367837438,"user":{"displayName":"Archit Sorathiya","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16296646542609532734"},"user_tz":-330},"id":"MuXvuqoo31hU","outputId":"0936bd31-f3cf-4427-af9d-bcc3c2c6346a"},"outputs":[],"source":["base_model_vgg = keras.applications.VGG16(\n","    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n","    input_shape=(150, 150, 3),\n","    include_top=False,\n",")  # Do not include the ImageNet classifier at the top.\n","\n","# Freeze the base_model\n","\n","base_model_vgg.trainable = False\n","\n","# base_model_rs = keras.applications.ResNet(\n","#     weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n","#     input_shape=(150, 150, 3),\n","#     include_top=False,\n","# )  # Do not include the ImageNet classifier at the top.\n","\n","# # Freeze the base_model\n","# base_model_rs.trainable = True\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Create new model on top\n","inputs1 = keras.Input(shape=(150, 150, 3), name=\"inputs1\")\n","inputs2 = keras.Input(shape=(150, 150, 3), name=\"inputs2\")\n","inputs3 = keras.Input(shape=(150, 150, 3), name=\"inputs3\")\n","inputs4 = keras.Input(shape=(150, 150, 3), name=\"inputs4\")\n","inputs5 = keras.Input(shape=(150, 150, 3), name=\"inputs5\")\n","inputs6 = keras.Input(shape=(150, 150, 3), name=\"inputs6\")\n","inputs7 = keras.Input(shape=(150, 150, 3), name=\"inputs7\")\n","inputs8 = keras.Input(shape=(150, 150, 3), name=\"inputs8\")\n","inputs9 = keras.Input(shape=(150, 150, 3), name=\"inputs9\")\n","inputs10 = keras.Input(shape=(150, 150, 3), name=\"inputs10\")\n","inputs11 = keras.Input(shape=(150, 150, 3), name=\"inputs11\")\n","inputs12 = keras.Input(shape=(150, 150, 3), name=\"inputs12\")\n","\n","def multi_branch_build(inputs, base_model):\n","\n","    # inputs = keras.Input(shape=(150, 150, 3))\n","    # x = data_augmentation(inputs)  # Apply random data augmentation\n","\n","    x = inputs\n","    # Pre-trained Xception weights requires that input be scaled\n","    # from (0, 255) to a range of (-1., +1.), the rescaling layer\n","    # outputs: `(inputs * scale) + offset`\n","    scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n","    x = scale_layer(x)\n","\n","    # The base model contains batchnorm layers. We want to keep them in inference mode\n","    # when we unfreeze the base model for fine-tuning, so we make sure that the\n","    # base_model is running in inference mode here.\n","    x = base_model(x, training=False)\n","    # x=keras.layers.GlobalAveragePooling2D()(x)\n","  # Regularize with dropout\n","    return x\n","\n","x1 = multi_branch_build(inputs = inputs1, base_model=base_model_vgg)\n","x2 = multi_branch_build(inputs = inputs2, base_model=base_model_vgg)\n","x3 = multi_branch_build(inputs = inputs3, base_model=base_model_vgg)\n","x4 = multi_branch_build(inputs = inputs4, base_model=base_model_vgg)\n","x5 = multi_branch_build(inputs = inputs5, base_model=base_model_vgg)\n","x6 = multi_branch_build(inputs = inputs6, base_model=base_model_vgg)\n","x7 = multi_branch_build(inputs = inputs7, base_model=base_model_vgg)\n","x8 = multi_branch_build(inputs = inputs8, base_model=base_model_vgg)\n","x9 = multi_branch_build(inputs = inputs9, base_model=base_model_vgg)\n","x10 = multi_branch_build(inputs = inputs10, base_model=base_model_vgg)\n","x11 = multi_branch_build(inputs = inputs11, base_model=base_model_vgg)\n","x12 = multi_branch_build(inputs = inputs12, base_model=base_model_vgg)\n","\n","y = keras.layers.concatenate([x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12])\n","y = keras.layers.GlobalAveragePooling2D()(y)\n","y = keras.layers.Dropout(0.2)(y)\n","y = keras.layers.Dense(256, activation='relu')(y)\n","y = keras.layers.Dropout(0.2)(y)\n","y = keras.layers.Dense(128, activation='relu')(y)\n","outputs = keras.layers.Dense(1)(y)\n","model = keras.Model([inputs1, inputs2, inputs3, inputs4, inputs5, inputs6, inputs7, inputs8, inputs9, inputs10, inputs11, inputs12], outputs)\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use conda to install these two packages!!!\n","\n","# !conda install graphviz\n","# !conda install pydot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tf.keras.utils.plot_model(model)\n"]},{"cell_type":"markdown","metadata":{"id":"otmJeA2m4-fM"},"source":["## **Now let's Train our Top Layer**\n","\n","Note from the above summary that we only have 2,049 trainable paramaters."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"405n0IfT4fZG"},"outputs":[],"source":["seed = 42\n","random.seed(seed)\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","keras.utils.set_random_seed(seed)\n","\n","\n","model.compile(\n","    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-3),\n","    loss=keras.losses.MeanSquaredError(),\n","    metrics=[keras.metrics.MeanSquaredError()],\n","    # batch_size=32\n",")\n","\n","es = EarlyStopping(monitor='val_loss', patience=100)\n","epochs = 500\n","\n","model.fit(train_ds, \n","        epochs=epochs, \n","        validation_data=test_ds,\n","        callbacks = [es])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.plot(model.history.history['loss'], label='loss')\n","plt.plot(model.history.history['val_loss'], label = 'val_loss')\n","\n","plt.xlabel('Epoch')\n","plt.ylabel('LOSS')\n","plt.legend(loc='upper right')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.evaluate(test_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_pred = model.predict(test_ds)\n","\n","from scipy.stats import pearsonr\n","correlation, _ = pearsonr(np.array(y_pred.reshape(32)), np.array(test_labels))\n","print(correlation)"]}],"metadata":{"colab":{"name":"21. Keras Transfer Learning and Fine Tuning.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":0}
